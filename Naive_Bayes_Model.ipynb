{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a31a77e4-9a6d-4818-862e-d738a99dcc26",
   "metadata": {},
   "source": [
    "## Naive Bayes Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a8556289-90d6-43a6-b35a-bc88433b1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "743be334-cafd-4d98-ad21-ba805129bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/meldrumapple/Desktop/Bayes/Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b355f7aa-c7a0-46f6-bc49-0dbc100d17ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import test and train data set as a result of Data_engineering code\n",
    "test=pd.read_csv('test.csv')\n",
    "train=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "39b9eebb-d322-4a1a-a113-bc2972846ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust score range to start at zero for varaibles age, income, education for ease of code later\n",
    "train['Age']=train['Age']-1\n",
    "train['Income']=train['Income']-1\n",
    "train['Education']=train['Education']-1\n",
    "train['GenHlth']=train['GenHlth']-1\n",
    "test['Age']=test['Age']-1\n",
    "test['Income']=test['Income']-1\n",
    "test['Education']=test['Education']-1\n",
    "test['GenHlth']=test['GenHlth']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5fb70840-7eef-46c5-8f6b-80eadbfa4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train data set by response variable\n",
    "train_0=train[train['Diabetes_012']==0]\n",
    "train_1=train[train['Diabetes_012']==1]\n",
    "train_2=train[train['Diabetes_012']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0392f-12de-43c4-a9e7-bfd501e17c8d",
   "metadata": {},
   "source": [
    "likelihood of any given combination of variable reponses: \n",
    "$$\n",
    "p(X|c_i)=\\prod_{j=0}^{J}P(x_j|c_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6e66f180-9224-4ca0-8b59-b825e36f182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that gets likelihood of every combination of class and variable reponse for any variable\n",
    "def get_like(variable,responses):\n",
    "    like_0=list()\n",
    "    like_1=list()\n",
    "    like_2=list()\n",
    "    for x in responses: \n",
    "        like_0.append(len(train_0[train_0[variable]==x])/len(train_0))\n",
    "        like_1.append(len(train_1[train_1[variable]==x])/len(train_1))\n",
    "        like_2.append(len(train_2[train_2[variable]==x])/len(train_2))\n",
    "    return pd.DataFrame({'like_0':like_0, 'like_1':like_1, 'like_2':like_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7986b914-76b4-4429-a6da-18a89634b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary of dataframe for each variable\n",
    "likes=list()\n",
    "#add binary variable dataframes to dict\n",
    "likes.append(get_like('HighBP',[0,1]))\n",
    "likes.append(get_like('HighChol',[0,1]))\n",
    "likes.append(get_like('CholCheck',[0,1]))\n",
    "likes.append(get_like('BMI', list(range(0,5))))\n",
    "likes.append(get_like('Smoker',[0,1]))\n",
    "likes.append(get_like('Stroke',[0,1]))\n",
    "likes.append(get_like('HeartDiseaseorAttack',[0,1]))\n",
    "likes.append(get_like('PhysActivity',[0,1]))\n",
    "likes.append(get_like('Fruits',[0,1]))\n",
    "likes.append(get_like('Veggies',[0,1]))\n",
    "likes.append(get_like('HvyAlcoholConsump',[0,1]))\n",
    "likes.append(get_like('AnyHealthcare',[0,1]))\n",
    "likes.append(get_like('GenHlth',[0,1]))\n",
    "likes.append(get_like('GenHlth', list(range(0,6))))\n",
    "likes.append(get_like('MentHlth', list(range(0,3))))\n",
    "likes.append(get_like('PhysHlth', list(range(0,3))))\n",
    "likes.append(get_like('DiffWalk',[0,1]))\n",
    "likes.append(get_like('Sex',[0,1]))\n",
    "likes.append(get_like('Age', list(range(0,14))))\n",
    "likes.append(get_like('Education', list(range(0,7))))\n",
    "likes.append(get_like('Income', list(range(0,9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268dfad-a193-4dd0-bca0-03c84c967b1d",
   "metadata": {},
   "source": [
    "Priors:\n",
    "$$\n",
    "P(c_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "54874c95-678f-4d62-9156-435d6f6e198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the priors\n",
    "pri_0=len(train_0)/len(train)\n",
    "pri_1=len(train_1)/len(train)\n",
    "pri_2=len(train_2)/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a179c-a510-4024-aed0-cd9a5d66549d",
   "metadata": {},
   "source": [
    "condition for classification:\n",
    "$$\n",
    "argmax(P(c_j)[\\prod_{j=0}^{J}P(x_j|c_i)+\\alpha])\n",
    "$$\n",
    "\n",
    "we added a laplace smoothing factor because some x_i responses are not present in class c_j so they would result in a likelihood of zero which would give a posterior probability of zero for that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1ebf8bed-bd87-477b-b77a-ff01946ba971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_obs(row):\n",
    "    like_0=1\n",
    "    like_1=1\n",
    "    like_2=1\n",
    "    for i in range(len(row)):\n",
    "        like_0*=likes[i].iloc[int(row[i]),0].round(15)+0.001 #alpha in case frequency is zero for any variable\n",
    "        like_1*=likes[i].iloc[int(row[i]),1].round(15)+0.001\n",
    "        like_2*=likes[i].iloc[int(row[i]),2].round(15)+0.001\n",
    "    post_0=like_0*(pri_0)\n",
    "    post_1=like_1*(pri_1)\n",
    "    post_2=like_2*(pri_2)\n",
    "    dct={post_0:0,post_1:1,post_2:2}\n",
    "    return dct[max(post_0,post_1,post_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ecd5facf-b9c9-49d0-bc0c-01298d516033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply to test data:\n",
    "true_val=test.iloc[:,2].astype(int)\n",
    "predictors=test.iloc[:,3:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9941cc6e-53cf-48ba-88e4-88b9ae1c85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all rows of the prediction variables and record most likely classfication\n",
    "preds=list()\n",
    "for j in range(len(test)):\n",
    "    preds.append(class_obs(list(predictors.iloc[j, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "88c43270-ec67-418f-bcd6-ff268e3f43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({'dia_hat':preds, 'dia':true_val})\n",
    "results['correct']=(results['dia_hat']==results['dia'])*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "331a3cd5-42ea-4800-bcbf-953768532ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8393054241564175"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results['correct'])/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc9daa-f745-4274-8504-183a096ee064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
